import cv2
import numpy as np
import time
from collections import deque
import onnxruntime as ort
from picamera2 import Picamera2
import os
import pickle
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import pygame

# --- ì„¤ì • (Configuration) ---
ONNX_MODEL_PATH = "final_detection416.onnx"
INPUT_WIDTH = 416
INPUT_HEIGHT = 416
CONF_THRESHOLD = 0.4
NMS_THRESHOLD = 0.4
labels = ["Person", "Cigarette", "Smoke", "Fire"]

# (â˜… 2ê°œì˜ ì‚¬ìš´ë“œ íŒŒì¼ ë° "ì´ ì£¼ê¸°" ì„¤ì •)
GUIDE_FILE = "person.mp3"     # ì•ˆë‚´ìš© (ì‚¬ëŒë§Œ)
WARNING_FILE = "smoke.mp3"   # ê²½ê³ ìš© (ì‚¬ëŒ+ë‹´ë°°)
GUIDE_CYCLE = 15             # (â˜…) ì•ˆë‚´ ì´ ì£¼ê¸° (ì¬ìƒ 10ì´ˆ + íœ´ì‹ 5ì´ˆ)
WARNING_CYCLE = 31           # (â˜…) ê²½ê³  ì´ ì£¼ê¸° (ì¬ìƒ 16ì´ˆ + íœ´ì‹ 15ì´ˆ)

# --- Google Drive API ì„¤ì • ---
SCOPES = ['https://www.googleapis.com/auth/drive.file']

def get_drive_service():
    """Google Drive API ì„œë¹„ìŠ¤ ê°ì²´ë¥¼ ì¸ì¦í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    creds = None
    if os.path.exists('token.pickle'):
        with open('token.pickle', 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        with open('token.pickle', 'wb') as token:
            pickle.dump(creds, token)
    return build('drive', 'v3', credentials=creds)

def get_or_create_folder(folder_name, service):
    """ì§€ì •í•œ ì´ë¦„ì˜ í´ë”ë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ ìƒì„±í•œ ë’¤ í´ë” IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
    response = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()
    files = response.get('files', [])
    
    if files:
        folder_id = files[0].get('id')
        print(f"âœ… Folder '{folder_name}' already exists. ID: {folder_id}")
        return folder_id
    else:
        file_metadata = {'name': folder_name, 'mimeType': 'application/vnd.google-apps.folder'}
        folder = service.files().create(body=file_metadata, fields='id').execute()
        folder_id = folder.get('id')
        print(f"âœ… Folder '{folder_name}' created. ID: {folder_id}")
        return folder_id

def upload_to_drive(file_path, file_name, service, folder_id):
    """ì§€ì •í•œ í´ë” ID ì•ˆì— íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        mimetype = 'video/mp4' if file_path.endswith('.mp4') else 'image/jpeg'
        media = MediaFileUpload(file_path, mimetype=mimetype)
        file_metadata = {'name': file_name, 'parents': [folder_id]}
        file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        print(f"âœ… File '{file_name}' uploaded successfully into folder.")
        os.remove(file_path) # ì—…ë¡œë“œ í›„ ë¡œì»¬ íŒŒì¼ ì‚­ì œ
    except Exception as e:
        print(f"âŒ Failed to upload {file_name}. Error: {e}")

# --- ONNX ëª¨ë¸ ì´ˆê¸°í™” ---
try:
    session = ort.InferenceSession(ONNX_MODEL_PATH, providers=['CPUExecutionProvider'])
    print(f"âœ… ONNX Model loaded successfully: {ONNX_MODEL_PATH}")
    model_inputs = session.get_inputs()
    input_name = model_inputs[0].name
    model_outputs = session.get_outputs()
    output_name = model_outputs[0].name
except Exception as e:
    print(f"âŒ ONNX Model loading failed: {e}")
    exit()

# --- Picamera2 ì´ˆê¸°í™” ---
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(
    main={"format": "RGB888", "size": (INPUT_WIDTH, INPUT_HEIGHT)}
))
picam2.start()
time.sleep(1)
print("âœ… Camera ready")


# --- (â˜…) Pygame Mixer ì´ˆê¸°í™” (ë…¸ì´ì¦ˆ ë°©ì§€ ì„¤ì • í¬í•¨) ---
try:
    pygame.mixer.init(frequency=44100, buffer=4096)
    guide_sound = None
    warning_sound = None

    if os.path.exists(GUIDE_FILE):
        guide_sound = pygame.mixer.Sound(GUIDE_FILE)
        print(f"âœ… Guide sound loaded: {GUIDE_FILE}")
    else:
        print(f"âŒ Warning: Guide sound not found at {GUIDE_FILE}")
        
    if os.path.exists(WARNING_FILE):
        warning_sound = pygame.mixer.Sound(WARNING_FILE)
        print(f"âœ… Warning sound loaded: {WARNING_FILE}")
    else:
        print(f"âŒ Warning: Warning sound not found at {WARNING_FILE}")
        
except Exception as e:
    print(f"âŒ Failed to initialize pygame mixer: {e}")
    guide_sound = None
    warning_sound = None


cv2.namedWindow("YOLOv8 ONNX Detection", cv2.WINDOW_NORMAL)

# --- ë³€ìˆ˜ ì´ˆê¸°í™” ---
prev_time = time.time(); frame_count = 0; fps = 0
detection_window = 10; required_duration = 3
person_timestamps = deque(); smoking_timestamps = deque()
last_upload_time = 0; upload_interval = 30 
BUFFER_SIZE = 150
frame_buffer = deque(maxlen=BUFFER_SIZE)

# (â˜… "ìŠ¤ë§ˆíŠ¸ ì¿¨íƒ€ì„"ì„ ìœ„í•œ 2ê°œì˜ ì‹œê°„ ë³€ìˆ˜)
last_guide_play_time = 0
last_warning_play_time = 0


# --- êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì„œë¹„ìŠ¤ ë° í´ë” ì´ˆê¸°í™” ---
try:
    drive_service = get_drive_service()
    print("âœ… Google Drive service initialized.")
    photo_folder_id = get_or_create_folder("Photos", drive_service)
    video_folder_id = get_or_create_folder("Videos", drive_service)
except Exception as e:
    print(f"âŒ Failed to initialize Google Drive: {e}")
    drive_service = None 


try:
    while True:
        current_time = time.time()
        
        # 1. ì¹´ë©”ë¼ ìº¡ì²˜
        frame_bgr = picam2.capture_array()
        
        # 2. ë²„í¼ ì €ì¥
        frame_buffer.append(frame_bgr.copy()) 

        # 3. RGB ë³€í™˜
        frame_rgb_for_model = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        
        # 4. í…ì„œ ìƒì„±
        input_tensor = np.transpose(frame_rgb_for_model, (2, 0, 1)) # HWC -> CHW
        input_tensor = np.expand_dims(input_tensor, axis=0).astype(np.float32) / 255.0
        
        # 5. ONNX ì¶”ë¡ 
        outputs = session.run([output_name], {input_name: input_tensor})[0]
        
        # 6. í›„ì²˜ë¦¬ (NMS)
        predictions = np.squeeze(outputs).T
        boxes, confidences, class_ids = [], [], []
        class_counts = {label: 0 for label in labels}

        for pred in predictions:
            class_probs = pred[4:]
            class_id = np.argmax(class_probs)
            confidence = class_probs[class_id]
            
            if confidence > CONF_THRESHOLD:
                cx, cy, w, h = pred[0], pred[1], pred[2], pred[3]
                x1 = int(cx - w / 2); y1 = int(cy - h / 2)
                boxes.append([x1, y1, int(w), int(h)])
                confidences.append(float(confidence))
                class_ids.append(class_id)
                
        indices = cv2.dnn.NMSBoxes(boxes, confidences, CONF_THRESHOLD, NMS_THRESHOLD)

        # 7. ê²°ê³¼ ê·¸ë¦¬ê¸°
        if len(indices) > 0:
            for i in indices.flatten():
                if class_ids[i] < len(labels):
                    class_name = labels[class_ids[i]]
                    class_counts[class_name] += 1
                    
                    box = boxes[i]; x1, y1, w, h = box[0], box[1], box[2], box[3]; conf = confidences[i]
                    color = (0, 255, 0) # Person
                    
                    if class_name == "Cigarette": color = (0, 0, 255)
                    elif class_name == "Smoke": color = (255, 165, 0)
                    elif class_name == "Fire": color = (0, 255, 255)
                    
                    label = f"{class_name} ({conf:.2f})"
                    cv2.rectangle(frame_bgr, (x1, y1), (x1 + w, y1 + h), color, 2)
                    cv2.putText(frame_bgr, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # 8. FPS ê³„ì‚°
        frame_count += 1; elapsed_time = current_time - prev_time
        if elapsed_time >= 1.0:
            fps = frame_count / elapsed_time; frame_count = 0; prev_time = current_time
        
        # 9. ê²½ê³  ë¡œì§
        person_detected = class_counts["Person"] > 0
        cigarette_detected = class_counts["Cigarette"] > 0
        
        if person_detected: person_timestamps.append(current_time)
        if person_detected and cigarette_detected: smoking_timestamps.append(current_time)
            
        while person_timestamps and current_time - person_timestamps[0] > detection_window: person_timestamps.popleft()
        while smoking_timestamps and current_time - smoking_timestamps[0] > detection_window: smoking_timestamps.popleft()
            
        person_duration = len(person_timestamps) / fps if fps > 0 else 0
        smoking_duration = len(smoking_timestamps) / fps if fps > 0 else 0
        
        show_smoking_warning = smoking_duration >= required_duration
        show_person_guide = person_duration >= required_duration and not show_smoking_warning

        # 10. ì •ë³´ í‘œì‹œ
        y_offset = 20
        for name, count in class_counts.items():
            if count > 0:
                cv2.putText(frame_bgr, f"{name}: {count}", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                y_offset += 25
        
        
        # --- (â˜…) 11. ìµœì¢… "ìŠ¤ë§ˆíŠ¸ ì¿¨íƒ€ì„" ìŒì„± ì•ˆë‚´ ë¡œì§ (ìˆ˜ì •ë¨) ---
        
        # 1ë‹¨ê³„: ë¬´ëŒ€ í™•ì¸ (ëŠê¹€ ë°©ì§€)
        if not pygame.mixer.get_busy():
            
            # 2ë‹¨ê³„: ì¿¨íƒ€ì„ ë° ìš°ì„ ìˆœìœ„ í™•ì¸ (ìŠ¤í”¼ì»¤ê°€ ì¡°ìš©í•  ë•Œë§Œ)
            
            # 1ìˆœìœ„: ê²½ê³  (í¡ì—°)
            # ê²½ê³  "ì´ ì£¼ê¸°"(31ì´ˆ)ê°€ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
            if show_smoking_warning and (current_time - last_warning_play_time > WARNING_CYCLE):
                if warning_sound:
                    print(f"[{time.strftime('%H:%M:%S')}] ğŸ”Š Playing WARNING sound (smoke.mp3)!")
                    warning_sound.play()
                    last_warning_play_time = current_time
                    last_guide_play_time = current_time # (â˜…) ê²½ê³  ì‹œ ì•ˆë‚´ ì¿¨íƒ€ì„ë„ í•¨ê»˜ ë¦¬ì…‹
            
            # 2ìˆœìœ„: ì•ˆë‚´ (ì‚¬ëŒ)
            # (ê²½ê³ ê°€ ì•„ë‹ˆê³ ) ì•ˆë‚´ "ì´ ì£¼ê¸°"(15ì´ˆ)ê°€ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
            elif show_person_guide and (current_time - last_guide_play_time > GUIDE_CYCLE):
                if guide_sound:
                    print(f"[{time.strftime('%H:%M:%S')}] ğŸ”Š Playing GUIDE sound (person.mp3)!")
                    guide_sound.play()
                    last_guide_play_time = current_time

        
        # --- 12. í…ìŠ¤íŠ¸ í‘œì‹œ ë° ì—…ë¡œë“œ ë¡œì§ (ìŒì„± ì¬ìƒê³¼ ë³„ê°œë¡œ í•­ìƒ ì‹¤í–‰) ---
        
        if show_smoking_warning:
            # 1. (ì‚¬ëŒ + ë‹´ë°°): ê²½ê³  í…ìŠ¤íŠ¸
            cv2.putText(frame_bgr, "WARNING: Smoking Detected!", (10, y_offset + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)
            
            # 11. ì—…ë¡œë“œ ë¡œì§ (ê²½ê³  í…ìŠ¤íŠ¸ê°€ í‘œì‹œë  ë•Œ ì‹¤í–‰)
            if drive_service and (current_time - last_upload_time > upload_interval):
                last_upload_time = current_time
                print(f"[{time.strftime('%H:%M:%S')}] Smoking event triggered! Preparing to upload...")
                timestamp_str = time.strftime("%Y%m%d_%H%M%S")
                photo_name = f"smoking_snapshot_{timestamp_str}.jpg"
                video_name = f"smoking_video_{timestamp_str}.mp4"

                cv2.imwrite(photo_name, frame_bgr)
                
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                record_fps = fps if fps > 0 else 10.0
                writer = cv2.VideoWriter(video_name, fourcc, record_fps, (INPUT_WIDTH, INPUT_HEIGHT))
                for buffered_frame in list(frame_buffer):
                    writer.write(buffered_frame)
                writer.release()
                
                upload_to_drive(photo_name, photo_name, drive_service, photo_folder_id)
                upload_to_drive(video_name, video_name, drive_service, video_folder_id)
        
        elif show_person_guide:
            # 2. (ì‚¬ëŒë§Œ): ì•ˆë‚´ í…ìŠ¤íŠ¸
            cv2.putText(frame_bgr, "No-Smoking Area", (10, y_offset + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)
        
        
        cv2.putText(frame_bgr, f"FPS: {fps:.2f}", (10, y_offset + 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # 13. ìµœì¢… í™”ë©´ í‘œì‹œ
        cv2.imshow("YOLOv8 ONNX Detection", frame_bgr)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("ğŸ›‘ Program terminated")
finally:
    cv2.destroyAllWindows()
    picam2.stop()
    pygame.mixer.quit()
    print("âœ… Camera, windows, and sound mixer closed")